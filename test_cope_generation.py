#!/usr/bin/env python3
"""
Test script to analyze behavioral CSV files and show the exact cope names 
that would be generated by the current fMRI analysis code.
"""

import pandas as pd
import os
from pathlib import Path

def analyze_conditions_from_csv(csv_file):
    """Analyze conditions from a behavioral CSV file and show how they would be processed."""
    print(f"\n{'='*60}")
    print(f"ANALYZING: {os.path.basename(csv_file)}")
    print(f"{'='*60}")
    
    # Read the CSV file
    df = pd.read_csv(csv_file, sep='\t')
    
    # Show original conditions
    print("\nüìä ORIGINAL CONDITIONS FROM CSV:")
    condition_counts = df['trial_type'].value_counts()
    for condition, count in condition_counts.items():
        print(f"  {condition}: {count} trials")
    
    # Simulate the condition processing logic from utils.py
    print("\nüîÑ CONDITION PROCESSING (simulating utils.py logic):")
    
    raw_conditions = list(df['trial_type'].values)
    cs_count = raw_conditions.count('CS-_first_half')
    
    if cs_count > 1:
        # Multiple CS- trials: split into CS-_first_half_first and CS-_first_half_others
        conditions = ['CS-_first_half_first', 'CS-_first_half_others']
        # Add other unique conditions (excluding CS-_first_half)
        other_conditions = [c for c in set(raw_conditions) if c != 'CS-_first_half']
        conditions.extend(other_conditions)
        print(f"  ‚úÖ Split {cs_count} CS-_first_half trials into:")
        print(f"     - CS-_first_half_first (1 trial)")
        print(f"     - CS-_first_half_others ({cs_count-1} trials)")
    else:
        # Single or no CS- trials: use original logic
        conditions = list(set(raw_conditions))
        print(f"  ‚ÑπÔ∏è  Using standard conditions: {len(conditions)} total")
    
    print(f"\n  üìã FINAL PROCESSED CONDITIONS:")
    for i, condition in enumerate(conditions):
        print(f"     {i+1:2d}. {condition}")
    
    # Simulate the contrast generation logic from first_level_workflows.py
    print("\nüéØ CONTRAST GENERATION (simulating first_level_workflows.py logic):")
    
    # Extract CS- conditions with grouping
    cs_first_trial = None
    cs_other_trials = []
    other_conditions = []
    
    if 'CS-_first_half_first' in conditions:
        cs_first_trial = 'CS-_first_half_first'
        print(f"  ‚úÖ Found CS-_first_half_first condition")
    
    if 'CS-_first_half_others' in conditions:
        cs_other_trials = ['CS-_first_half_others']
        print(f"  ‚úÖ Found CS-_first_half_others condition")
    
    # Process all other conditions (non-CS conditions)
    for condition in conditions:
        if condition not in ['CS-_first_half_first', 'CS-_first_half_others']:
            other_conditions.append(condition)
    
    # Create list of all conditions for contrast generation (EXCLUDING cs_first_trial and US* conditions)
    all_contrast_conditions = []
    # NOTE: cs_first_trial is NOT added to contrast conditions - it exists only for model fitting
    if cs_other_trials:
        all_contrast_conditions.append('CS-_first_half_others')  # Keep original name
    
    # Add other conditions EXCEPT US* conditions, SHOCK, and FIXATION*
    for condition in other_conditions:
        if not condition.startswith('US_') and condition != 'SHOCK' and not condition.startswith('FIXATION'):
            all_contrast_conditions.append(condition)
    
    print(f"\n  üìã CONDITIONS FOR CONTRAST GENERATION:")
    print(f"     NOTE: CS-_first_half_first, all US* conditions, SHOCK, and FIXATION* are EXCLUDED from all copes")
    print(f"     (kept only for model fitting)")
    for i, condition in enumerate(all_contrast_conditions):
        print(f"     {i+1:2d}. {condition}")
    
    # Show which US* conditions, SHOCK, and FIXATION* were excluded
    us_conditions = [c for c in other_conditions if c.startswith('US_')]
    shock_conditions = [c for c in other_conditions if c == 'SHOCK']
    fixation_conditions = [c for c in other_conditions if c.startswith('FIXATION')]
    excluded_conditions = us_conditions + shock_conditions + fixation_conditions
    if excluded_conditions:
        print(f"\n     üö´ CONDITIONS EXCLUDED from all copes:")
        for excl_cond in excluded_conditions:
            print(f"        - {excl_cond}")
    
    # Generate standard contrasts
    print(f"\n  üîÑ GENERATING STANDARD CONTRASTS:")
    contrasts = []
    
    # Pairwise comparisons only (no baseline contrasts)
    print(f"     üìä Pairwise comparisons:")
    pair_count = 0
    for i, cond1 in enumerate(all_contrast_conditions):
        for j, cond2 in enumerate(all_contrast_conditions):
            if i < j:  # Avoid duplicate contrasts
                pair_count += 1
                contrast_name = f"{cond1}>{cond2}"
                contrasts.append((contrast_name, 'T', [cond1, cond2], [1, -1]))
                print(f"       {pair_count:2d}. {contrast_name}")
                
                pair_count += 1
                contrast_name = f"{cond1}<{cond2}"
                contrasts.append((contrast_name, 'T', [cond1, cond2], [-1, 1]))
                print(f"       {pair_count:2d}. {contrast_name}")
    
    print(f"\n  üìà TOTAL CONTRASTS GENERATED: {len(contrasts)}")
    print(f"     (CS-_first_half_first, US* conditions, SHOCK, and FIXATION* excluded from all copes)")
    
    # Show the exact cope names that would be created
    print(f"\nüéØ EXACT COPE NAMES (cope1, cope2, cope3, etc.):")
    print(f"     NOTE: CS-_first_half_first, US* conditions, SHOCK, and FIXATION* have NO copes - kept only for model fitting")
    for i, (name, contrast_type, conditions, weights) in enumerate(contrasts):
        cope_num = i + 1
        print(f"     cope{cope_num:2d}: {name}")
    
    return conditions, contrasts

def main():
    """Main function to analyze all behavioral CSV files."""
    print("üß† fMRI ANALYSIS - COPE NAME GENERATION ANALYSIS")
    print("=" * 60)
    print("This script analyzes behavioral CSV files and shows exactly")
    print("what cope names would be generated by the current fMRI code.")
    print("=" * 60)
    
    # Path to behavioral data
    behav_dir = "/Users/xiaoqianxiao/projects/NARSAD/MRI/source_data/behav"
    
    # Find all relevant CSV files
    csv_files = []
    for file in os.listdir(behav_dir):
        if file.endswith('.csv') and 'half_events' in file:
            csv_files.append(os.path.join(behav_dir, file))
    
    csv_files.sort()  # Sort for consistent output
    
    print(f"\nüìÅ Found {len(csv_files)} behavioral CSV files to analyze:")
    for file in csv_files:
        print(f"  - {os.path.basename(file)}")
    
    # Analyze each file
    all_results = {}
    for csv_file in csv_files:
        try:
            conditions, contrasts = analyze_conditions_from_csv(csv_file)
            all_results[os.path.basename(csv_file)] = {
                'conditions': conditions,
                'contrasts': contrasts
            }
        except Exception as e:
            print(f"\n‚ùå ERROR analyzing {os.path.basename(csv_file)}: {e}")
    
    # Summary
    print(f"\n{'='*60}")
    print("üìä SUMMARY OF ALL FILES")
    print(f"{'='*60}")
    
    for filename, results in all_results.items():
        print(f"\nüìÅ {filename}:")
        print(f"  - Conditions: {len(results['conditions'])}")
        print(f"  - Contrasts: {len(results['contrasts'])}")
        print(f"  - Copes: cope1 to cope{len(results['contrasts'])}")
    
    print(f"\n‚úÖ Analysis complete! The cope names above show exactly what")
    print("   will be generated when you run the fMRI analysis on the supercomputer.")

if __name__ == "__main__":
    main()
